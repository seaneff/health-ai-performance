algorithm_metric_id,algorithm_name,algorithm_version,metric_name,output,sample_type,start_date,end_date,country,population_name,population_details,sample_size,value,lower_ci95,upper_ci95,value_details,reference
1,EnsoSleep,N/A,sensitivity,Sleep-Wake staging,validation,,,NR,Adult,"""Demographics including sex, age, BMI, weight, and height, to establish representative adult (N=100) PSG studies from which PPG samples were obtained.""
Double blinded scoring was prospectively collected for each PSG by 3 experienced RPSGTs randomized from a pool of 6 scorers. RR was established by mode when two scorers agreed on RR value and median otherwise."" Country and date ranges not reported.",100,0.96,NR,NR,"""AI EEG-S/W demonstrated 96%/94%/95% Sensitivity, Specificity, and Accuracy compared to RPSGT 2/3 consensus PSG staging.""","Watson NF, Fernandez C, Rusk S, et al. Clinical Validation of Artificial Intelligence (AI) Analysis of Photoplethysmogram (PPG) Based Sleep-Wake Staging, Total Sleep Time, and Respiratory Rate."
2,EnsoSleep,N/A,specificity,Sleep-Wake staging,validation,,,NR,Adult,"""Demographics including sex, age, BMI, weight, and height, to establish representative adult (N=100) PSG studies from which PPG samples were obtained.""
Double blinded scoring was prospectively collected for each PSG by 3 experienced RPSGTs randomized from a pool of 6 scorers. RR was established by mode when two scorers agreed on RR value and median otherwise."" Country and date ranges not reported.",100,0.94,NR,NR,"""AI EEG-S/W demonstrated 96%/94%/95% Sensitivity, Specificity, and Accuracy compared to RPSGT 2/3 consensus PSG staging.""","Watson NF, Fernandez C, Rusk S, et al. Clinical Validation of Artificial Intelligence (AI) Analysis of Photoplethysmogram (PPG) Based Sleep-Wake Staging, Total Sleep Time, and Respiratory Rate."
3,EnsoSleep,N/A,accuracy,Sleep-Wake staging,validation,,,NR,Adult,"""Demographics including sex, age, BMI, weight, and height, to establish representative adult (N=100) PSG studies from which PPG samples were obtained.""
Double blinded scoring was prospectively collected for each PSG by 3 experienced RPSGTs randomized from a pool of 6 scorers. RR was established by mode when two scorers agreed on RR value and median otherwise."" Country and date ranges not reported.",100,0.95,NR,NR,"""AI EEG-S/W demonstrated 96%/94%/95% Sensitivity, Specificity, and Accuracy compared to RPSGT 2/3 consensus PSG staging.""","Watson NF, Fernandez C, Rusk S, et al. Clinical Validation of Artificial Intelligence (AI) Analysis of Photoplethysmogram (PPG) Based Sleep-Wake Staging, Total Sleep Time, and Respiratory Rate."
4,EnsoSleep,N/A,sensitivity,Total Sleep Time,validation,,,NR,Adult,"""Demographics including sex, age, BMI, weight, and height, to establish representative adult (N=100) PSG studies from which PPG samples were obtained.""
Double blinded scoring was prospectively collected for each PSG by 3 experienced RPSGTs randomized from a pool of 6 scorers. RR was established by mode when two scorers agreed on RR value and median otherwise."" Country and date ranges not reported.",100,0.90,NR,NR,"""AI EEG-S/W demonstrated 96%/94%/95% Sensitivity, Specificity, and Accuracy compared to RPSGT 2/3 consensus PSG staging. AI PPG-S/W demonstrated 90%/89%/90% Sensitivity, Specificity, and Accuracy compared to the same PSG panel.""","Watson NF, Fernandez C, Rusk S, et al. Clinical Validation of Artificial Intelligence (AI) Analysis of Photoplethysmogram (PPG) Based Sleep-Wake Staging, Total Sleep Time, and Respiratory Rate."
5,EnsoSleep,N/A,specificity,Total Sleep Time,validation,,,NR,Adult,"""Demographics including sex, age, BMI, weight, and height, to establish representative adult (N=100) PSG studies from which PPG samples were obtained.""
Double blinded scoring was prospectively collected for each PSG by 3 experienced RPSGTs randomized from a pool of 6 scorers. RR was established by mode when two scorers agreed on RR value and median otherwise."" Country and date ranges not reported.",100,0.89,NR,NR,"""AI EEG-S/W demonstrated 96%/94%/95% Sensitivity, Specificity, and Accuracy compared to RPSGT 2/3 consensus PSG staging. AI PPG-S/W demonstrated 90%/89%/90% Sensitivity, Specificity, and Accuracy compared to the same PSG panel.""","Watson NF, Fernandez C, Rusk S, et al. Clinical Validation of Artificial Intelligence (AI) Analysis of Photoplethysmogram (PPG) Based Sleep-Wake Staging, Total Sleep Time, and Respiratory Rate."
6,EnsoSleep,N/A,accuracy,Total Sleep Time,validation,,,NR,Adult,"""Demographics including sex, age, BMI, weight, and height, to establish representative adult (N=100) PSG studies from which PPG samples were obtained.""
Double blinded scoring was prospectively collected for each PSG by 3 experienced RPSGTs randomized from a pool of 6 scorers. RR was established by mode when two scorers agreed on RR value and median otherwise."" Country and date ranges not reported.",100,0.90,NR,NR,"""AI EEG-S/W demonstrated 96%/94%/95% Sensitivity, Specificity, and Accuracy compared to RPSGT 2/3 consensus PSG staging. AI PPG-S/W demonstrated 90%/89%/90% Sensitivity, Specificity, and Accuracy compared to the same PSG panel.""","Watson NF, Fernandez C, Rusk S, et al. Clinical Validation of Artificial Intelligence (AI) Analysis of Photoplethysmogram (PPG) Based Sleep-Wake Staging, Total Sleep Time, and Respiratory Rate."
7,EnsoSleep,N/A,ROC AUC,Sleep-Wake staging,validation,,,NR,Adult,"""Demographics including sex, age, BMI, weight, and height, to establish representative adult (N=100) PSG studies from which PPG samples were obtained.""
Double blinded scoring was prospectively collected for each PSG by 3 experienced RPSGTs randomized from a pool of 6 scorers. RR was established by mode when two scorers agreed on RR value and median otherwise."" Country and date ranges not reported.",100,0.96,NR,NR,"""Receiver operating characteristic (ROC) curves comparing sleep/wake (S/W) differentiation for A) AI PPG-S/W vs. RPSGT 2/3 consensus-S/W and B) AI EEG-S/W vs RPSGT 2/3 consensus-S/W from over 92,000 epochs of sleep from 100 patients. The AUC was robust for both AI PPG-S/W (0.96) and AI EEG-S/W (0.99) indicating both methods are highly accurate at differentiating sleep from wake.""","Watson NF, Fernandez C, Rusk S, et al. Clinical Validation of Artificial Intelligence (AI) Analysis of Photoplethysmogram (PPG) Based Sleep-Wake Staging, Total Sleep Time, and Respiratory Rate."
8,EnsoSleep,N/A,ROC AUC,Total Sleep Time,validation,,,NR,Adult,"""Demographics including sex, age, BMI, weight, and height, to establish representative adult (N=100) PSG studies from which PPG samples were obtained.""
Double blinded scoring was prospectively collected for each PSG by 3 experienced RPSGTs randomized from a pool of 6 scorers. RR was established by mode when two scorers agreed on RR value and median otherwise."" Country and date ranges not reported.",100,0.98,NR,NR,"""Receiver operating characteristic (ROC) curves comparing sleep/wake (S/W) differentiation for A) AI PPG-S/W vs. RPSGT 2/3 consensus-S/W and B) AI EEG-S/W vs RPSGT 2/3 consensus-S/W from over 92,000 epochs of sleep from 100 patients. The AUC was robust for both AI PPG-S/W (0.96) and AI EEG-S/W (0.99) indicating both methods are highly accurate at differentiating sleep from wake.""","Watson NF, Fernandez C, Rusk S, et al. Clinical Validation of Artificial Intelligence (AI) Analysis of Photoplethysmogram (PPG) Based Sleep-Wake Staging, Total Sleep Time, and Respiratory Rate."
9,PPD risk prediction model (Zhang et al),N/A,ROC AUC,Diagnosis of postpartum depression (1 year after childbirth),development,1/1/2015,6/30/2018,United States,Postpartum people,"""Two EHR datasets containing data on 15,197 women from 2015 to 2018 at a single site, and 53,972 women from 2004 to 2017 at multiple sites were used as development and validation sets, respectively, to construct the PPD risk prediction model.""",15197,0.937,0.912,0.962,"""The model performances as measured by area under the receiver operating characteristic curve (AUC) are 0.937 (95% CI 0.912 - 0.962) and 0.886 (95% CI 0.879-0.893) in the development and validation datasets, respectively.""","Zhang Y, Wang S, Hermann A, Joly R, Pathak J. Development and validation of a machine learning algorithm for predicting the risk of postpartum depression among pregnant women. Journal of Affective Disorders. 2021;279:1-8. doi:10.1016/j.jad.2020.09.113"
10,PPD risk prediction model (Zhang et al),N/A,ROC AUC,Diagnosis of postpartum depression (1 year after childbirth),validation,1/1/2015,6/30/2018,United States,Postpartum people,"""Two EHR datasets containing data on 15,197 women from 2015 to 2018 at a single site, and 53,972 women from 2004 to 2017 at multiple sites were used as development and validation sets, respectively, to construct the PPD risk prediction model.""",53972,0.886,0.879,0.893,"""The model performances as measured by area under the receiver operating characteristic curve (AUC) are 0.937 (95% CI 0.912 - 0.962) and 0.886 (95% CI 0.879-0.893) in the development and validation datasets, respectively.""","Zhang Y, Wang S, Hermann A, Joly R, Pathak J. Development and validation of a machine learning algorithm for predicting the risk of postpartum depression among pregnant women. Journal of Affective Disorders. 2021;279:1-8. doi:10.1016/j.jad.2020.09.113"
11,PPD risk prediction model (Munk-Olsen et al),N/A,ROC AUC,Recorded contact to a psychiatric treatment facility or redeemed antidepressant prescriptions (6 months after childbirth),development,1/1/1997,12/31/2012,Denmark,Postpartum people,"""Danish population registers served as our data sources and PPD was defined as recorded contact to a psychiatric treatment facility (ICD-10 code DF32-33) or redeemed antidepressant prescriptions (ATC code N06A), resulting in a sample of 6,402 PPD cases (development sample) and 2,379 (validation sample).""",6402,0.809,0.804,0.815,For Ext+ model (table 3),"Munk-Olsen T, Liu X, Madsen KB, et al. Postpartum depression: a developed and validated model predicting individual risk in new mothers. Transl Psychiatry. 2022;12(1):1-10. doi:10.1038/s41398-022-02190-8
"
12,PPD risk prediction model (Munk-Olsen et al),N/A,ROC AUC,Recorded contact to a psychiatric treatment facility or redeemed antidepressant prescriptions (6 months after childbirth),validation,1/1/2013,12/31/2015,Denmark,Postpartum people,"""Danish population registers served as our data sources and PPD was defined as recorded contact to a psychiatric treatment facility (ICD-10 code DF32-33) or redeemed antidepressant prescriptions (ATC code N06A), resulting in a sample of 6,402 PPD cases (development sample) and 2,379 (validation sample).""",2379,0.812,0.804,0.820,For Ext+ model (table 3),"Munk-Olsen T, Liu X, Madsen KB, et al. Postpartum depression: a developed and validated model predicting individual risk in new mothers. Transl Psychiatry. 2022;12(1):1-10. doi:10.1038/s41398-022-02190-8
"
13,PPD risk prediction model (Munk-Olsen et al),N/A,ROC AUC,Recorded contact to a psychiatric treatment facility or redeemed antidepressant prescriptions (6 months after childbirth),development,1/1/1997,12/31/2012,Denmark,Postpartum people,"""Danish population registers served as our data sources and PPD was defined as recorded contact to a psychiatric treatment facility (ICD-10 code DF32-33) or redeemed antidepressant prescriptions (ATC code N06A), resulting in a sample of 6,402 PPD cases (development sample) and 2,379 (validation sample).""",6402,0.801 ,0.796,0.807,For Ext model (table 3),"Munk-Olsen T, Liu X, Madsen KB, et al. Postpartum depression: a developed and validated model predicting individual risk in new mothers. Transl Psychiatry. 2022;12(1):1-10. doi:10.1038/s41398-022-02190-8"
14,PPD risk prediction model (Munk-Olsen et al),N/A,ROC AUC,Recorded contact to a psychiatric treatment facility or redeemed antidepressant prescriptions (6 months after childbirth),validation,1/1/2013,12/31/2015,Denmark,Postpartum people,"""Danish population registers served as our data sources and PPD was defined as recorded contact to a psychiatric treatment facility (ICD-10 code DF32-33) or redeemed antidepressant prescriptions (ATC code N06A), resulting in a sample of 6,402 PPD cases (development sample) and 2,379 (validation sample).""",2379,0.808,0.800,0.816,For Ext model (table 3),"Munk-Olsen T, Liu X, Madsen KB, et al. Postpartum depression: a developed and validated model predicting individual risk in new mothers. Transl Psychiatry. 2022;12(1):1-10. doi:10.1038/s41398-022-02190-8"
15,PPD risk prediction model (Munk-Olsen et al),N/A,ROC AUC,Recorded contact to a psychiatric treatment facility or redeemed antidepressant prescriptions (6 months after childbirth),development,1/1/1997,12/31/2012,Denmark,Postpartum people,"""Danish population registers served as our data sources and PPD was defined as recorded contact to a psychiatric treatment facility (ICD-10 code DF32-33) or redeemed antidepressant prescriptions (ATC code N06A), resulting in a sample of 6,402 PPD cases (development sample) and 2,379 (validation sample).""",6402,0.795,0.790,0.802,For core model (table 3),"Munk-Olsen T, Liu X, Madsen KB, et al. Postpartum depression: a developed and validated model predicting individual risk in new mothers. Transl Psychiatry. 2022;12(1):1-10. doi:10.1038/s41398-022-02190-8"
16,PPD risk prediction model (Munk-Olsen et al),N/A,ROC AUC,Recorded contact to a psychiatric treatment facility or redeemed antidepressant prescriptions (6 months after childbirth),validation,1/1/2013,12/31/2015,Denmark,Postpartum people,"""Danish population registers served as our data sources and PPD was defined as recorded contact to a psychiatric treatment facility (ICD-10 code DF32-33) or redeemed antidepressant prescriptions (ATC code N06A), resulting in a sample of 6,402 PPD cases (development sample) and 2,379 (validation sample).""",2379,0.804 ,0.796,0.812,For core model (table 3),"Munk-Olsen T, Liu X, Madsen KB, et al. Postpartum depression: a developed and validated model predicting individual risk in new mothers. Transl Psychiatry. 2022;12(1):1-10. doi:10.1038/s41398-022-02190-8"
17,VBAC calculator (including race),N/A,ROC AUC,Successful vaginal delivery,validation,1/1/2016,12/31/2019,United States,Laboring people,"All patients who underwent a trial of labor after c-section between January 2016 and December 2019 in Mount Sanai Hospital in NYC; excluding multilple c-sections, multiple gestations, incomplete records, and/or missing race and ethnicity data",1241,0.77,NR,NR,"""Table 5 presents one model that uses Grobman et al.’s variables in predicting TOLAC success (model 1) and another that uses Grobman et al.’s variables except race and ethnicity (model 2). In the prior MFMU calculator, race and ethnicity were categorized as African-American, Hispanic, or Other. Our study stratified race into four categories; these four categories were used in model 1. In model 1, there was insufficient evidence to conclude that race and ethnicity were associated with the probability of successful TOLAC (p = 0.065). The area under the curve (AUC) was used to assess the predictive ability of each model. AUCs for models 1 and 2 were 0.77 and 0.78, respectively.""","Buckley A, Sestito S, Ogundipe T, et al. Racial and Ethnic Disparities Among Women Undergoing a Trial of Labor After Cesarean Delivery: Performance of the VBAC Calculator with and without Patients’ Race/Ethnicity. Reprod Sci. 2022;29(7):2030-2038. doi:10.1007/s43032-022-00959-2"
18,VBAC calculator (excluding race),N/A,ROC AUC,Successful vaginal delivery,validation,1/1/2016,12/31/2019,United States,Laboring people,"All patients who underwent a trial of labor after c-section between January 2016 and December 2019 in Mount Sanai Hospital in NYC; excluding multilple c-sections, multiple gestations, incomplete records, and/or missing race and ethnicity data",1241,0.78,NR,NR,"""Table 5 presents one model that uses Grobman et al.’s variables in predicting TOLAC success (model 1) and another that uses Grobman et al.’s variables except race and ethnicity (model 2). In the prior MFMU calculator, race and ethnicity were categorized as African-American, Hispanic, or Other. Our study stratified race into four categories; these four categories were used in model 1. In model 1, there was insufficient evidence to conclude that race and ethnicity were associated with the probability of successful TOLAC (p = 0.065). The area under the curve (AUC) was used to assess the predictive ability of each model. AUCs for models 1 and 2 were 0.77 and 0.78, respectively.""","Buckley A, Sestito S, Ogundipe T, et al. Racial and Ethnic Disparities Among Women Undergoing a Trial of Labor After Cesarean Delivery: Performance of the VBAC Calculator with and without Patients’ Race/Ethnicity. Reprod Sci. 2022;29(7):2030-2038. doi:10.1007/s43032-022-00959-2"
19,VBAC calculator (including race),N/A,ROC AUC,Successful vaginal delivery,validation,1/1/2018,12/31/2019,Israel,Laboring people,"""women admitted at a single university affiliated medical center, between January 1st, 2018 and December 31th 2019. All women carrying singleton, cephalic presentation pregnancy at term with previous one low transverse caesarean delivery (CD) who opt for trial of VBAC were included""",490,0.709,0.652,0.766,"""Compared to the original publication, the MFMU calculator underperformed for prediction of VBAC: ROC-AUC 0.709, 95% CI 0.652–0.766, p=0.00, with sensitivity 67.42%, specificity 65.96%, positive & negative predictive value 89.30% and 32.46%, respectively and total accuracy of 67.14%.""","Haggiag N, Eitan S, Maor-Sagie E, Hallak M, Gabbay-Benziv R. External validation of MFMUs vaginal birth after cesarean delivery calculator and construction of improved model. American Journal of Obstetrics & Gynecology. 2022;226(1):S311-S312. doi:10.1016/j.ajog.2021.11.524"
20,VBAC calculator (including race),N/A,sensitivity,Successful vaginal delivery,validation,1/1/2018,12/31/2019,Israel,Laboring people,"""women admitted at a single university affiliated medical center, between January 1st, 2018 and December 31th 2019. All women carrying singleton, cephalic presentation pregnancy at term with previous one low transverse caesarean delivery (CD) who opt for trial of VBAC were included""",490,0.6742,NR,NR,"""Compared to the original publication, the MFMU calculator underperformed for prediction of VBAC: ROC-AUC 0.709, 95% CI 0.652–0.766, p=0.00, with sensitivity 67.42%, specificity 65.96%, positive & negative predictive value 89.30% and 32.46%, respectively and total accuracy of 67.14%.""","Haggiag N, Eitan S, Maor-Sagie E, Hallak M, Gabbay-Benziv R. External validation of MFMUs vaginal birth after cesarean delivery calculator and construction of improved model. American Journal of Obstetrics & Gynecology. 2022;226(1):S311-S312. doi:10.1016/j.ajog.2021.11.524"
21,VBAC calculator (including race),N/A,specificity,Successful vaginal delivery,validation,1/1/2018,12/31/2019,Israel,Laboring people,"""women admitted at a single university affiliated medical center, between January 1st, 2018 and December 31th 2019. All women carrying singleton, cephalic presentation pregnancy at term with previous one low transverse caesarean delivery (CD) who opt for trial of VBAC were included""",490,0.6596,NR,NR,"""Compared to the original publication, the MFMU calculator underperformed for prediction of VBAC: ROC-AUC 0.709, 95% CI 0.652–0.766, p=0.00, with sensitivity 67.42%, specificity 65.96%, positive & negative predictive value 89.30% and 32.46%, respectively and total accuracy of 67.14%.""","Haggiag N, Eitan S, Maor-Sagie E, Hallak M, Gabbay-Benziv R. External validation of MFMUs vaginal birth after cesarean delivery calculator and construction of improved model. American Journal of Obstetrics & Gynecology. 2022;226(1):S311-S312. doi:10.1016/j.ajog.2021.11.524"
22,VBAC calculator (including race),N/A,positive predictive value,Successful vaginal delivery,validation,1/1/2018,12/31/2019,Israel,Laboring people,"""women admitted at a single university affiliated medical center, between January 1st, 2018 and December 31th 2019. All women carrying singleton, cephalic presentation pregnancy at term with previous one low transverse caesarean delivery (CD) who opt for trial of VBAC were included""",490,0.8930,NR,NR,"""Compared to the original publication, the MFMU calculator underperformed for prediction of VBAC: ROC-AUC 0.709, 95% CI 0.652–0.766, p=0.00, with sensitivity 67.42%, specificity 65.96%, positive & negative predictive value 89.30% and 32.46%, respectively and total accuracy of 67.14%.""","Haggiag N, Eitan S, Maor-Sagie E, Hallak M, Gabbay-Benziv R. External validation of MFMUs vaginal birth after cesarean delivery calculator and construction of improved model. American Journal of Obstetrics & Gynecology. 2022;226(1):S311-S312. doi:10.1016/j.ajog.2021.11.524"
23,VBAC calculator (including race),N/A,negative predictive value,Successful vaginal delivery,validation,1/1/2018,12/31/2019,Israel,Laboring people,"""women admitted at a single university affiliated medical center, between January 1st, 2018 and December 31th 2019. All women carrying singleton, cephalic presentation pregnancy at term with previous one low transverse caesarean delivery (CD) who opt for trial of VBAC were included""",490,0.3246,NR,NR,"""Compared to the original publication, the MFMU calculator underperformed for prediction of VBAC: ROC-AUC 0.709, 95% CI 0.652–0.766, p=0.00, with sensitivity 67.42%, specificity 65.96%, positive & negative predictive value 89.30% and 32.46%, respectively and total accuracy of 67.14%.""","Haggiag N, Eitan S, Maor-Sagie E, Hallak M, Gabbay-Benziv R. External validation of MFMUs vaginal birth after cesarean delivery calculator and construction of improved model. American Journal of Obstetrics & Gynecology. 2022;226(1):S311-S312. doi:10.1016/j.ajog.2021.11.524"
24,VBAC calculator (including race),N/A,accuracy,Successful vaginal delivery,validation,1/1/2018,12/31/2019,Israel,Laboring people,"""women admitted at a single university affiliated medical center, between January 1st, 2018 and December 31th 2019. All women carrying singleton, cephalic presentation pregnancy at term with previous one low transverse caesarean delivery (CD) who opt for trial of VBAC were included""",490,0.6714,NR,NR,"""Compared to the original publication, the MFMU calculator underperformed for prediction of VBAC: ROC-AUC 0.709, 95% CI 0.652–0.766, p=0.00, with sensitivity 67.42%, specificity 65.96%, positive & negative predictive value 89.30% and 32.46%, respectively and total accuracy of 67.14%.""","Haggiag N, Eitan S, Maor-Sagie E, Hallak M, Gabbay-Benziv R. External validation of MFMUs vaginal birth after cesarean delivery calculator and construction of improved model. American Journal of Obstetrics & Gynecology. 2022;226(1):S311-S312. doi:10.1016/j.ajog.2021.11.524"
25,VBAC calculator (excluding race),N/A,ROC AUC,Successful vaginal delivery,validation,1/1/1999,12/31/2002,United States,Laboring people,"""individuals were included in this analysis if they were delivered on or after 37 0/7 weeks’ gestation with a live singleton cephalic fetus at the time of labor and delivery admission, had a trial of labor after cesarean delivery, and had a history of 1 previous low-transverse cesarean delivery""",11687,0.75,0.74,0.77,"""The model had excellent calibration between predicted and empirical probabilities and, when applied to the overall analytical population, an area under the receiver operating characteristic curve of 0.75 (95% confidence interval, 0.74–0.77)""","Grobman WA, Sandoval G, Rice MM, et al. Prediction of vaginal birth after cesarean delivery in term gestations: a calculator without race and ethnicity. American Journal of Obstetrics & Gynecology. 2021;225(6):664.e1-664.e7. doi:10.1016/j.ajog.2021.05.021
"
26,VBAC calculator (excluding race),N/A,ROC AUC,Successful vaginal delivery,validation,1/1/2012,12/31/2021,Japan,Laboring people,"""Japanese women with a single pregnancy with cephalic presentation at a gestational age of >37 weeks who had previously undergone only 1 lower segment cesarean delivery and who had attempted trial of labor after cesarean delivery (TOLAC)""",94,0.76,0.66,0.86,"""During the study period, 94 women attempted TOLAC. Of these, 70 had a vaginal delivery with a success rate of 74.5%. Clinical characteristics are shown in the Table. Our sample size was sufficient with 99% power. Using the above variables, we determined that the AUC was 0.76 (95% confidence interval, 0.66–0.86), as shown in the Figure. This result was similar to that reported by Grobman et al""","Sugai S, Nishijima K. Validating a calculator without race and ethnicity to predict vaginal birth after cesarean delivery. American Journal of Obstetrics & Gynecology. 2022;227(3):537-538. doi:10.1016/j.ajog.2022.05.017"
27,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.86,0.85,0.88,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
28,Stanford CBC (Hemoglobin) model,N/A,ROC AUC,Abnormal Hemoglobin lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.88,0.86,0.89,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
29,Stanford CBC (Platelets) model,N/A,ROC AUC,Abnormal Platelet lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.79,0.77,0.82,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
30,Stanford CBC (White blood cell) model,N/A,ROC AUC,Abnormal White blood cell lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.76,0.74,0.79,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
31,Stanford Metabolic panel (Albumin) model,N/A,ROC AUC,Abnormal Albumin lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.88,0.86,0.91,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
32,Stanford Metabolic panel (Blood urea nitrogen) model,N/A,ROC AUC,Abnormal Blood urea nitrogen lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.85,0.83,0.87,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
33,Stanford Metabolic panel (Calcium) model,N/A,ROC AUC,Abnormal Calcium lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.80,0.76,0.83,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
34,Stanford Metabolic panel (Carbon dioxide) model,N/A,ROC AUC,Abnormal Carbon dioxide lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.69,0.66,0.72,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
35,Stanford Metabolic panel (Creatinine) model,N/A,ROC AUC,Abnormal Creatinine lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.78,0.75,0.80,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
36,Stanford Metabolic panel (Potassium),N/A,ROC AUC,Abnormal Potassium lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.67,0.61,0.72,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
37,Stanford Metabolic panel (Sodium) model,N/A,ROC AUC,Abnormal Sodium lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.79,0.75,0.82,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
38,Stanford Magnesium model,N/A,ROC AUC,Abnormal Magnesium lab value,validation,1/1/2019,12/31/2021,United States,Adult,"""retrospective cohorts contained data from 2015 to 2021, with two thousand diagnostic tests sampled randomly per year for a total of 14,000 orders per task """,14000,0.70,0.67,0.73,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
39,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",18982,0.83,0.83,0.84,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
40,Stanford CBC (Hemoglobin) model,N/A,ROC AUC,Abnormal Hemoglobin lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",18982,0.83,0.83,0.84,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
41,Stanford CBC (Platelets) model,N/A,ROC AUC,Abnormal Platelet lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",18982,0.77,0.76,0.78,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
42,Stanford CBC (White blood cell) model,N/A,ROC AUC,Abnormal White blood cell lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",18982,0.69,0.68,0.70,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
43,Stanford Metabolic panel (Albumin) model,N/A,ROC AUC,Abnormal Albumin lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",16441,0.85,0.84,0.86,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
44,Stanford Metabolic panel (Blood urea nitrogen) model,N/A,ROC AUC,Abnormal Blood urea nitrogen lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",16441,0.80,0.79,0.81,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
45,Stanford Metabolic panel (Calcium) model,N/A,ROC AUC,Abnormal Calcium lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",16441,0.79,0.78,0.81,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
46,Stanford Metabolic panel (Carbon dioxide) model,N/A,ROC AUC,Abnormal Carbon dioxide lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",16441,0.62,0.61,0.63,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
47,Stanford Metabolic panel (Creatinine) model,N/A,ROC AUC,Abnormal Creatinine lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",16441,0.75,0.74,0.76,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
48,Stanford Metabolic panel (Potassium),N/A,ROC AUC,Abnormal Potassium lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",16441,0.60,0.59,0.62,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
49,Stanford Metabolic panel (Sodium) model,N/A,ROC AUC,Abnormal Sodium lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",16441,0.71,0.70,0.72,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
50,Stanford Magnesium model,N/A,ROC AUC,Abnormal Magnesium lab value,real-world use,1/1/2019,12/31/2021,United States,Adult,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",5234,0.65,0.63,0.67,See Table 2,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
51,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",7103,0.85,0.83,0.88,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
52,Stanford CBC (Hemoglobin) model,N/A,ROC AUC,Abnormal Hemoglobin lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",7103,0.88,0.86,0.90,"See Supplemental Table 4
","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
53,Stanford CBC (Platelets) model,N/A,ROC AUC,Abnormal Platelet lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",7103,0.80,0.77,0.84,See Supplemental Table 6,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
54,Stanford CBC (White blood cell) model,N/A,ROC AUC,Abnormal White blood cell lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",7103,0.77,0.73,0.80,See Supplemental Table 5,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
55,Stanford Metabolic panel (Albumin) model,N/A,ROC AUC,Abnormal Albumin lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",6923,0.89,0.86,0.91,See Supplemental Table 7,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
56,Stanford Metabolic panel (Blood urea nitrogen) model,N/A,ROC AUC,Abnormal Blood urea nitrogen lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",6923,0.84,0.81,0.88,See Supplemental Table 8,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
57,Stanford Metabolic panel (Calcium) model,N/A,ROC AUC,Abnormal Calcium lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",6923,0.76,0.70,0.81,See Supplemental Table 9,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
58,Stanford Metabolic panel (Carbon dioxide) model,N/A,ROC AUC,Abnormal Carbon dioxide lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",6923,0.67,0.62,0.71,"See Supplemental Table 10
","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
59,Stanford Metabolic panel (Creatinine) model,N/A,ROC AUC,Abnormal Creatinine lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",6923,0.76,0.73,0.80,See Supplemental Table 11,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
60,Stanford Metabolic panel (Potassium),N/A,ROC AUC,Abnormal Potassium lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",6923,0.65,0.57,0.72,See Supplemental Table 12,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
61,Stanford Metabolic panel (Sodium) model,N/A,ROC AUC,Abnormal Sodium lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",6923,0.78,0.73,0.80,See Supplemental Table 13,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
62,Stanford Magnesium model,N/A,ROC AUC,Abnormal Magnesium lab value,validation,1/1/2019,12/31/2021,United States,Female sex,"""retrospective cohorts contained data from 2015 to 2021""",5234,0.71,0.66,0.75,See Supplemental Table 14,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
63,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",10092,0.83,0.82,0.84,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
64,Stanford CBC (Hemoglobin) model,N/A,ROC AUC,Abnormal Hemoglobin lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",10092,0.82,0.81,0.83,"See Supplemental Table 4
","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
65,Stanford CBC (Platelets) model,N/A,ROC AUC,Abnormal Platelet lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",10092,0.76,0.75,0.77,See Supplemental Table 6,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
66,Stanford CBC (White blood cell) model,N/A,ROC AUC,Abnormal White blood cell lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",10092,0.68,0.67,0.69,See Supplemental Table 5,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
67,Stanford Metabolic panel (Albumin) model,N/A,ROC AUC,Abnormal Albumin lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8711,0.86,0.85,0.87,See Supplemental Table 7,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
68,Stanford Metabolic panel (Blood urea nitrogen) model,N/A,ROC AUC,Abnormal Blood urea nitrogen lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8711,0.79,0.77,0.80,See Supplemental Table 8,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
69,Stanford Metabolic panel (Calcium) model,N/A,ROC AUC,Abnormal Calcium lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8711,0.78,0.76,0.80,See Supplemental Table 9,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
70,Stanford Metabolic panel (Carbon dioxide) model,N/A,ROC AUC,Abnormal Carbon dioxide lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8711,0.61,0.59,0.62,"See Supplemental Table 10
","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
71,Stanford Metabolic panel (Creatinine) model,N/A,ROC AUC,Abnormal Creatinine lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8711,0.74,0.73,0.75,See Supplemental Table 11,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
72,Stanford Metabolic panel (Potassium),N/A,ROC AUC,Abnormal Potassium lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8711,0.60,0.58,0.62,See Supplemental Table 12,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
73,Stanford Metabolic panel (Sodium) model,N/A,ROC AUC,Abnormal Sodium lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8711,0.71,0.69,0.72,See Supplemental Table 13,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
74,Stanford Magnesium model,N/A,ROC AUC,Abnormal Magnesium lab value,real-world use,1/1/2019,12/31/2021,United States,Female sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",2425,0.67,0.63,0.70,See Supplemental Table 14,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
75,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6259,0.87,0.84,0.89,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
76,Stanford CBC (Hemoglobin) model,N/A,ROC AUC,Abnormal Hemoglobin lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6259,0.88,0.86,0.90,"See Supplemental Table 4
","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
77,Stanford CBC (Platelets) model,N/A,ROC AUC,Abnormal Platelet lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6259,0.78,0.74,0.81,See Supplemental Table 6,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
78,Stanford CBC (White blood cell) model,N/A,ROC AUC,Abnormal White blood cell lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6259,0.76,0.73,0.80,See Supplemental Table 5,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
79,Stanford Metabolic panel (Albumin) model,N/A,ROC AUC,Abnormal Albumin lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6485,0.88,0.86,0.91,See Supplemental Table 7,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
80,Stanford Metabolic panel (Blood urea nitrogen) model,N/A,ROC AUC,Abnormal Blood urea nitrogen lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6485,0.85,0.82,0.87,See Supplemental Table 8,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
81,Stanford Metabolic panel (Calcium) model,N/A,ROC AUC,Abnormal Calcium lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6485,0.83,0.79,0.87,See Supplemental Table 9,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
82,Stanford Metabolic panel (Carbon dioxide) model,N/A,ROC AUC,Abnormal Carbon dioxide lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6485,0.71,0.66,0.76,"See Supplemental Table 10
","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
83,Stanford Metabolic panel (Creatinine) model,N/A,ROC AUC,Abnormal Creatinine lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6485,0.77,0.74,0.81,See Supplemental Table 11,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
84,Stanford Metabolic panel (Potassium),N/A,ROC AUC,Abnormal Potassium lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6485,0.68,0.62,0.71,See Supplemental Table 12,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
85,Stanford Metabolic panel (Sodium) model,N/A,ROC AUC,Abnormal Sodium lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6485,0.79,0.74,0.83,See Supplemental Table 13,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
86,Stanford Magnesium model,N/A,ROC AUC,Abnormal Magnesium lab value,validation,1/1/2019,12/31/2021,United States,Male sex,"""retrospective cohorts contained data from 2015 to 2021""",6338,0.70,0.66,0.74,See Supplemental Table 14,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
87,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8884,0.83,0.83,0.84,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
88,Stanford CBC (Hemoglobin) model,N/A,ROC AUC,Abnormal Hemoglobin lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8884,0.84,0.83,0.85,"See Supplemental Table 4
","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
89,Stanford CBC (Platelets) model,N/A,ROC AUC,Abnormal Platelet lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8884,0.78,0.77,0.79,See Supplemental Table 6,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
90,Stanford CBC (White blood cell) model,N/A,ROC AUC,Abnormal White blood cell lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",8884,0.70,0.69,0.71,See Supplemental Table 5,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
91,Stanford Metabolic panel (Albumin) model,N/A,ROC AUC,Abnormal Albumin lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",7724,0.84,0.83,0.85,See Supplemental Table 7,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
92,Stanford Metabolic panel (Blood urea nitrogen) model,N/A,ROC AUC,Abnormal Blood urea nitrogen lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",7724,0.80,0.78,0.81,See Supplemental Table 8,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
93,Stanford Metabolic panel (Calcium) model,N/A,ROC AUC,Abnormal Calcium lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",7724,0.81,0.79,0.82,See Supplemental Table 9,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
94,Stanford Metabolic panel (Carbon dioxide) model,N/A,ROC AUC,Abnormal Carbon dioxide lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",7724,0.63,0.61,0.64,"See Supplemental Table 10
","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
95,Stanford Metabolic panel (Creatinine) model,N/A,ROC AUC,Abnormal Creatinine lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",7724,0.75,0.74,0.76,See Supplemental Table 11,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
96,Stanford Metabolic panel (Potassium),N/A,ROC AUC,Abnormal Potassium lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",7724,0.60,0.58,0.63,See Supplemental Table 12,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
97,Stanford Metabolic panel (Sodium) model,N/A,ROC AUC,Abnormal Sodium lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",7724,0.72,0.70,0.73,See Supplemental Table 13,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
98,Stanford Magnesium model,N/A,ROC AUC,Abnormal Magnesium lab value,real-world use,1/1/2019,12/31/2021,United States,Male sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",2808,0.64,0.61,0.67,See Supplemental Table 14,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
99,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Asian,"""retrospective cohorts contained data from 2015 to 2021""",2444,0.85,0.81,0.88,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
100,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Black or African American,"""retrospective cohorts contained data from 2015 to 2021, in publication race identified as Black""",557,0.84,0.75,0.91,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
101,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Native American,"""retrospective cohorts contained data from 2015 to 2021""",44,0.87,0.55,1.00,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
102,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Pacific Islander,"""retrospective cohorts contained data from 2015 to 2021""",168,0.91,0.70,1.00,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
103,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Other race,"""retrospective cohorts contained data from 2015 to 2021""",2870,0.85,0.81,0.89,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
104,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Unknown race,"""retrospective cohorts contained data from 2015 to 2021""",391,0.80,0.66,0.90,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
105,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,White,"""retrospective cohorts contained data from 2015 to 2021""",6888,0.88,0.85,0.90,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
106,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,validation,1/1/2019,12/31/2021,United States,Over 40 years,"""retrospective cohorts contained data from 2015 to 2021""",,0.87,0.85,0.89,"See Supplemental Table 3, sample size not reported","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
107,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Asian,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",3612,0.85,0.83,0.86,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
108,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Black or African American,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",1060,0.79,0.76,0.81,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
109,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Native American,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",80,0.81,0.70,0.90,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
110,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Other race,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",4545,0.82,0.81,0.83,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
111,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Pacific Islander,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",294,0.85,0.81,0.89,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
112,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Unknown race,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",382,0.75,0.68,0.81,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
113,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,White,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",9009,0.84,0.83,0.85,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
114,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Over 40 years,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",382,0.84,0.83,0.85,"See Supplemental Table 3, sample size not reported","Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
115,Stanford CBC (Hematrocrit) model,N/A,ROC AUC,Abnormal Hematrocrit lab value,real-world use,1/1/2019,12/31/2021,United States,Unknown sex,"""Prospective cohorts were collected in real-time through Epic Chronicles as diagnostic orders triggered model inferences between January 11 and February 15, 2023""",,1.00,1.00,1.00,See Supplemental Table 3,"Corbin CK, Maclay R, Acharya A, et al. DEPLOYR: A technical framework for deploying custom real-time machine learning models into the electronic medical record. Published online March 10, 2023. Accessed July 21, 2023. http://arxiv.org/abs/2303.06269
"
116,IDx-DR,v2.3,sensitivity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,195,0.8769,0.8224,0.9195,See Table 3,US FDA. IDx-DRv2.3 510k Application.
117,IDx-DR,v2.3,specificity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,614,0.9007,0.8742,0.9232,See Table 3,US FDA. IDx-DRv2.3 510k Application.
118,IDx-DR,v2.3,positive predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,232,0.7371,0.6755,0.7925,See Table 4,US FDA. IDx-DRv2.3 510k Application.
119,IDx-DR,v2.3,negative predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,577,0.9584,0.9387,0.9732,See Table 4,US FDA. IDx-DRv2.3 510k Application.
120,IDx-DR,v2.0,sensitivity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,"Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.
",198,0.8737,0.8193,0.9166,See Table 3,US FDA. IDx-DRv2.3 510k Application.
121,IDx-DR,v2.0,specificity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,621,0.8953,0.8685,0.9183,See Table 3,US FDA. IDx-DRv2.3 510k Application.
122,IDx-DR,v2.0,positive predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,238,0.7269,0.6656,0.7825,See Table 4,US FDA. IDx-DRv2.3 510k Application.
123,IDx-DR,v2.0,negative predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,581,0.9570,0.9371,0.9720,See Table 4,US FDA. IDx-DRv2.3 510k Application.
124,IDx-DR,v1.0,sensitivity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,198,0.874,0.819,0.929,,US FDA. DE NOVO CLASSIFICATION REQUEST FOR IDX-DR.
125,IDx-DR,v1.0,specificity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,556,0.895,0.869,0.931,,US FDA. DE NOVO CLASSIFICATION REQUEST FOR IDX-DR.
126,IDx-DR,v1.0,positive predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,238,0.727,NR,NR,,US FDA. DE NOVO CLASSIFICATION REQUEST FOR IDX-DR.
127,IDx-DR,v1.0,negative predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,,,United States,Adult,Results calculated only among those for whom product was able to make a prediction. Date ranges not reported.,581,0.957,NR,NR,,US FDA. DE NOVO CLASSIFICATION REQUEST FOR IDX-DR.
128,EyeArt,v1.0,sensitivity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,4/17/2017,5/31/2018,United States,Primary care patients,"""The target population of the EyeArt pivotal clinical trial analysis was asymptomatic persons aged 22 years and older who were diagnosed with diabetes and not diagnosed with more than mild diabetic retinopathy."" Dates identified from clinicaltrails.gov record with ID: NCT03112005",11,1,0.741,1,"Results calculated per eye, based on results for EyeArt mtmDR output for wequentially enrolled cohort (See Table 2)",US FDA. EyeArt 510k Application.
129,EyeArt,v1.0,specificity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,4/17/2017,5/31/2018,United States,Primary care patients,"""The target population of the EyeArt pivotal clinical trial analysis was asymptomatic persons aged 22 years and older who were diagnosed with diabetes and not diagnosed with more than mild diabetic retinopathy."" Dates identified from clinicaltrails.gov record with ID: NCT03112005",75,0.92,0.851,0.975,"Results calculated per eye, based on results for EyeArt mtmDR output for wequentially enrolled cohort (See Table 2)",US FDA. EyeArt 510k Application.
130,EyeArt,v1.0,positive predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,4/17/2017,5/31/2018,United States,Primary care patients,"""The target population of the EyeArt pivotal clinical trial analysis was asymptomatic persons aged 22 years and older who were diagnosed with diabetes and not diagnosed with more than mild diabetic retinopathy."" Dates identified from clinicaltrails.gov record with ID: NCT03112005",17,0.647,0.40,0.857,"Results calculated per eye, based on results for EyeArt mtmDR output for wequentially enrolled cohort (See Table 2)",US FDA. EyeArt 510k Application.
131,EyeArt,v1.0,negative predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,4/17/2017,5/31/2018,United States,Primary care patients,"""The target population of the EyeArt pivotal clinical trial analysis was asymptomatic persons aged 22 years and older who were diagnosed with diabetes and not diagnosed with more than mild diabetic retinopathy."" Dates identified from clinicaltrails.gov record with ID: NCT03112005",69,1,0.947,1,"Results calculated per eye, based on results for EyeArt mtmDR output for wequentially enrolled cohort (See Table 2)",US FDA. EyeArt 510k Application.
132,EyeArt,v1.0,sensitivity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,4/17/2017,5/31/2018,United States,Ophthalmology patients,"""The target population of the EyeArt pivotal clinical trial analysis was asymptomatic persons aged 22 years and older who were diagnosed with diabetes and not diagnosed with more than mild diabetic retinopathy."" Dates identified from clinicaltrails.gov record with ID: NCT03112005",39,0.949,0.864,1,"Results calculated per eye, based on results for EyeArt mtmDR output for wequentially enrolled cohort (See Table 2)",US FDA. EyeArt 510k Application.
133,EyeArt,v1.0,specificity,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,4/17/2017,5/31/2018,United States,Ophthalmology patients,"""The target population of the EyeArt pivotal clinical trial analysis was asymptomatic persons aged 22 years and older who were diagnosed with diabetes and not diagnosed with more than mild diabetic retinopathy."" Dates identified from clinicaltrails.gov record with ID: NCT03112005",324,0.867,0.821,0.907,"Results calculated per eye, based on results for EyeArt mtmDR output for wequentially enrolled cohort (See Table 2)",US FDA. EyeArt 510k Application.
134,EyeArt,v1.0,positive predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,4/17/2017,5/31/2018,United States,Ophthalmology patients,"""The target population of the EyeArt pivotal clinical trial analysis was asymptomatic persons aged 22 years and older who were diagnosed with diabetes and not diagnosed with more than mild diabetic retinopathy."" Dates identified from clinicaltrails.gov record with ID: NCT03112005",80,0.462,0.322,0.590,"Results calculated per eye, based on results for EyeArt mtmDR output for wequentially enrolled cohort (See Table 2)",US FDA. EyeArt 510k Application.
15,EyeArt,v1.0,negative predictive value,Diagnosis of more than mild diabetic retinopathy (mtmDR),validation,4/17/2017,5/31/2018,United States,Ophthalmology patients,"""The target population of the EyeArt pivotal clinical trial analysis was asymptomatic persons aged 22 years and older who were diagnosed with diabetes and not diagnosed with more than mild diabetic retinopathy."" Dates identified from clinicaltrails.gov record with ID: NCT03112005",283,0.993,0.982,1,"Results calculated per eye, based on results for EyeArt mtmDR output for wequentially enrolled cohort (See Table 2)",US FDA. EyeArt 510k Application.
136,Bone Densitometer,N/A,Pearson correlation,Bone mineral density,validation,,,United States,Specific population not specified,"""cohort of asymptomatic cases who underwent CT scans."" Date ranges not reported.",172,0.72,NR,NR,"Significant correlations between BMD measurements by DXA and ABMD Software were found (r = 0.72 , p<0.01) ","U.S. Food & Drug Administration. Premarket Notification, 510(k). ABMD Software. 2022."
137,BriefCase for iPE Triage,N/A,sensitivity,Incidental Pulmonary Embolism (iPE) pathology,validation,,,United States,Adult,"""Aidoc conducted a retrospective, blinded, multicenter study with the BriefCase software with the primary endpoint to evaluate the software’s performance in identifying Contrast-enhanced chest CTs (but not dedicated CTPA protocol), containing Incidental Pulmonary Embolism in 268 cases from 2 clinical study sites in the US. There were 74 positive cases and 194 negative cases (images with iPE versus without iPE) included in the analysis."" // adult population specified elsewhere",268,0.905,0.814,0.962,"""Sensitivity and specificity exceeded the 80% performance goal. Specifically, sensitivity was 90.5% (95% CI: 81.4%, 96.2%) and specificity was 88.7% (95% CI: 83.3%, 92.8%)."" Date ranges not reported.","U.S. Food & Drug Administration. Premarket Notification, 510(k). BriefCase for iPE Triage. 2020. "
138,BriefCase for iPE Triage,N/A,specificity,Incidental Pulmonary Embolism (iPE) pathology,validation,,,United States,Adult,"""Aidoc conducted a retrospective, blinded, multicenter study with the BriefCase software with the primary endpoint to evaluate the software’s performance in identifying Contrast-enhanced chest CTs (but not dedicated CTPA protocol), containing Incidental Pulmonary Embolism in 268 cases from 2 clinical study sites in the US. There were 74 positive cases and 194 negative cases (images with iPE versus without iPE) included in the analysis."" // adult population specified elsewhere",268,0.887,0.833,0.928,"""Sensitivity and specificity exceeded the 80% performance goal. Specifically, sensitivity was 90.5% (95% CI: 81.4%, 96.2%) and specificity was 88.7% (95% CI: 83.3%, 92.8%)."" Date ranges not reported.","U.S. Food & Drug Administration. Premarket Notification, 510(k). BriefCase for iPE Triage. 2020. "
139,BriefCase for iPE Triage,N/A,sensitivity,Incidental Pulmonary Embolism (iPE) pathology,validation,,,Sweden,"Adult,Patients with cancer diagnosis","""Retrospective cohort study on patients with cancer with an elective CT study including the chest between 2018-07-01 and 2019-06-30. All study reports and images were reviewed to identify reported and unreported iPE and were processed by the AI algorithm.""",1069,0.907,NR,NR,"""The AI algorithm correctly identified 68 of 75 iPE with three false positives (sensitivity 90.7%, specificity 99.8%, PPV 95.6%, NPV 99.6%).""","Wiklund P, Medson K, Elf J. Incidental pulmonary embolism in patients with cancer: prevalence, underdiagnosis and evaluation of an AI algorithm for automatic detection of pulmonary embolism. Eur Radiol. 2023 Feb 1;33(2):1185–93. "
140,BriefCase for iPE Triage,N/A,specificity,Incidental Pulmonary Embolism (iPE) pathology,validation,7/1/2018,6/30/2019,Sweden,"Adult,Patients with cancer diagnosis","""Retrospective cohort study on patients with cancer with an elective CT study including the chest between 2018-07-01 and 2019-06-30. All study reports and images were reviewed to identify reported and unreported iPE and were processed by the AI algorithm.""",1069,0.998,NR,NR,"""The AI algorithm correctly identified 68 of 75 iPE with three false positives (sensitivity 90.7%, specificity 99.8%, PPV 95.6%, NPV 99.6%).""","Wiklund P, Medson K, Elf J. Incidental pulmonary embolism in patients with cancer: prevalence, underdiagnosis and evaluation of an AI algorithm for automatic detection of pulmonary embolism. Eur Radiol. 2023 Feb 1;33(2):1185–93. "
141,BriefCase for iPE Triage,N/A,positive predictive value,Incidental Pulmonary Embolism (iPE) pathology,validation,7/1/2018,6/30/2019,Sweden,"Adult,Patients with cancer diagnosis","""Retrospective cohort study on patients with cancer with an elective CT study including the chest between 2018-07-01 and 2019-06-30. All study reports and images were reviewed to identify reported and unreported iPE and were processed by the AI algorithm.""",1069,0.956,NR,NR,"""The AI algorithm correctly identified 68 of 75 iPE with three false positives (sensitivity 90.7%, specificity 99.8%, PPV 95.6%, NPV 99.6%).""","Wiklund P, Medson K, Elf J. Incidental pulmonary embolism in patients with cancer: prevalence, underdiagnosis and evaluation of an AI algorithm for automatic detection of pulmonary embolism. Eur Radiol. 2023 Feb 1;33(2):1185–93. "
142,BriefCase for iPE Triage,N/A,negative predictive value,Incidental Pulmonary Embolism (iPE) pathology,validation,7/1/2018,6/30/2019,Sweden,"Adult,Patients with cancer diagnosis","""Retrospective cohort study on patients with cancer with an elective CT study including the chest between 2018-07-01 and 2019-06-30. All study reports and images were reviewed to identify reported and unreported iPE and were processed by the AI algorithm.""",1069,0.996,NR,NR,"""The AI algorithm correctly identified 68 of 75 iPE with three false positives (sensitivity 90.7%, specificity 99.8%, PPV 95.6%, NPV 99.6%).""","Wiklund P, Medson K, Elf J. Incidental pulmonary embolism in patients with cancer: prevalence, underdiagnosis and evaluation of an AI algorithm for automatic detection of pulmonary embolism. Eur Radiol. 2023 Feb 1;33(2):1185–93. "
143,AWOL Tool,N/A,ROC AUC,Inpatient delerium,development,5/1/2010,11/1/2010,United States,"Older adults (50+ years),Hospital inpatients (non-ICU)","""All non-intensive care unit patients aged 50 years or older admitted through the emergency department to the medicine, cardiology, or neurology services were screened for eligibility through chart review or in person within 24 hours of admission by a trained research assistant.""",209,0.81,0.72,0.90,"""Area under the receiver operating characteristic curve for the derivation and validation cohorts was 0.81 (0.73–0.90) and 0.69 (0.54–0.83) respectively.""","Douglas VC, Hessler CS, Dhaliwal G, Betjemann JP, Fukuda KA, Alameddine LR, et al. The AWOL tool: Derivation and validation of a delirium prediction rule. Journal of Hospital Medicine. 2013 Sep;8(9):493–9. 
"
144,AWOL Tool,N/A,ROC AUC,Inpatient delerium,validation,10/1/2011,3/31/2012,United States,"Older adults (50+ years),Hospital inpatients (non-ICU)","""All non-intensive care unit patients aged 50 years or older admitted through the emergency department to the medicine, cardiology, or neurology services were screened for eligibility through chart review or in person within 24 hours of admission by a trained research assistant.""",165,0.69,0.54,0.83,"""Area under the receiver operating characteristic curve for the derivation and validation cohorts was 0.81 (0.73–0.90) and 0.69 (0.54–0.83) respectively.""","Douglas VC, Hessler CS, Dhaliwal G, Betjemann JP, Fukuda KA, Alameddine LR, et al. The AWOL tool: Derivation and validation of a delirium prediction rule. Journal of Hospital Medicine. 2013 Sep;8(9):493–9. 
"
145,AWOL Tool,N/A,ROC AUC,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",347,0.83,0.77,0.89,"""We calculated ROC curves for all patients that received an AWOL score, as well as for only patients that did not have prevalent delirium. For all patients, the area under the curve (AUC) was 0.83 (95% CI 0.77e0.89; Fig. 1A)."" This statistic is calculated INCLUDING patients who were delerious at the time that they were admitted into the ward.","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "
146,AWOL Tool,N/A,sensitivity,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",347,0.667,NR,NR,"""The sensitivity and specificity for diagnosing delirium at our cutoff score of 2 or greater were 66.7% and 89.2%, respectively (Table 5)."" This statistic is calculated INCLUDING patients who were delerious at the time that they were admitted into the ward.","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "
147,AWOL Tool,N/A,specificity,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",347,0.892,NR,NR,"""The sensitivity and specificity for diagnosing delirium at our cutoff score of 2 or greater were 66.7% and 89.2%, respectively (Table 5)."" This statistic is calculated INCLUDING patients who were delerious at the time that they were admitted into the ward.","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "
148,AWOL Tool,N/A,positive predictive value,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",347,0.605,NR,NR,"""The sensitivity and specificity for diagnosing delirium at our cutoff score of 2 or greater were 66.7% and 89.2%, respectively (Table 5). The positive predictive value was 60.5% and the negative predictive value was 91.5%."" This statistic is calculated INCLUDING patients who were delerious at the time that they were admitted into the ward.","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "
149,AWOL Tool,N/A,negative predictive value,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",347,0.915,NR,NR,"""The sensitivity and specificity for diagnosing delirium at our cutoff score of 2 or greater were 66.7% and 89.2%, respectively (Table 5). The positive predictive value was 60.5% and the negative predictive value was 91.5%."" This statistic is calculated INCLUDING patients who were delerious at the time that they were admitted into the ward.","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "
150,AWOL Tool,N/A,sensitivity,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (not delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",298,0.50,NR,NR,"""The sensitivity and specificity for predicting incident delirium only were 50.0% and 89.2%, respectively. In this group, the positive and negative predictive values were 25.0% and 96.1%, respectively.""","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "
151,AWOL Tool,N/A,specificity,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (not delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",298,0.892,NR,NR,"""The sensitivity and specificity for predicting incident delirium only were 50.0% and 89.2%, respectively. In this group, the positive and negative predictive values were 25.0% and 96.1%, respectively.""","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "
152,AWOL Tool,N/A,positive predictive value,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (not delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",298,0.25,NR,NR,"""The sensitivity and specificity for predicting incident delirium only were 50.0% and 89.2%, respectively. In this group, the positive and negative predictive values were 25.0% and 96.1%, respectively.""","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "
153,AWOL Tool,N/A,negative predictive value,Inpatient delerium,real-world use,4/1/2014,3/31/2015,United States,"Older adults (50+ years),Hospital inpatients (neurology or neurosciences),Hospital inpatients (not delirious upon admission)","""Patients were eligible for inclusion if they were age 50 or older and admitted to the neurosciences unit at the University of California San Francisco Medical Center between April 1st, 2014 and March 31st, 2015. The time frame was selected because it represented a year of admissions beginning 6 months after implementation of the delirium care pathway, to allow for nurse education and training. The neurosciences unit was selected because the unit’s nursing leadership identified delirious patients as a population that needed a more comprehensive and standardized care pathway. The majority of patients admitted to this unit are neurology and neurosurgical patients, although approximately 25% are on general medicine or other services as well (Table 1). From this population of 2909 patients, we randomly selected 800 hospital admissions for chart review using the “rand” function in Microsoft Excel 2010 version 2.0. Of these, all patients with an AWOL score recorded were included.""",298,0.961,NR,NR,"""The sensitivity and specificity for predicting incident delirium only were 50.0% and 89.2%, respectively. In this group, the positive and negative predictive values were 25.0% and 96.1%, respectively.""","Brown EG, Josephson SA, Anderson N, Reid M, Lee M, Douglas VC. Predicting inpatient delirium: The AWOL delirium risk-stratification score in clinical practice. Geriatric Nursing. 2017 Nov;38(6):567–72. "